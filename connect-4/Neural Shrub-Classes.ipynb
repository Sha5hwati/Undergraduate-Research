{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shashwati/anaconda3/envs/py35/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function returns the data in the right format\n",
    "def get_data():\n",
    "    dataset = np.genfromtxt(\"connect-4.csv\", dtype='str', delimiter=\",\")\n",
    "    \n",
    "    preX = dataset[:,0:42]\n",
    "    preY = dataset[:,42]\n",
    "    \n",
    "    X = np.zeros(preX.shape)\n",
    "    \n",
    "    for i, row in enumerate(preX):\n",
    "        for j, col in enumerate(row):\n",
    "            if col == 'x':\n",
    "                X[i,j] = 1.0\n",
    "            if col == 'o':\n",
    "                X[i,j] = -1.0\n",
    "            if col == 'b':\n",
    "                X[i,j] = 0.0\n",
    "    \n",
    "    \n",
    "    encoder = LabelEncoder()\n",
    "    # code: 0 - draw; 1 - loss; 2 -win\n",
    "    encoded_Y = encoder.fit_transform(preY)\n",
    "    \n",
    "    \n",
    "    # splitting the dataset into 80% training and 20% test data set\n",
    "    train, test, label_train, label_test = \\\n",
    "            train_test_split(X, encoded_Y,test_size = 0.2)\n",
    "    \n",
    "    return train, label_train, test, label_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree._tree import TREE_LEAF\n",
    "\n",
    "def prune_index(inner_tree, index, threshold):\n",
    "    if inner_tree.value[index].min() < threshold:\n",
    "        # turn node into a leaf by \"unlinking\" its children\n",
    "        inner_tree.children_left[index] = TREE_LEAF\n",
    "        inner_tree.children_right[index] = TREE_LEAF\n",
    "    # if there are shildren, visit them as well\n",
    "    if inner_tree.children_left[index] != TREE_LEAF:\n",
    "        prune_index(inner_tree, inner_tree.children_left[index], threshold)\n",
    "        prune_index(inner_tree, inner_tree.children_right[index], threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# builds the decision tree of depth 12\n",
    "def decision_tree(train, label):\n",
    "    dt = DecisionTreeClassifier(max_depth = 12, min_samples_leaf=100)\n",
    "    dt.fit(train, label)\n",
    "    prune_index(dt.tree_, 0, 5)\n",
    "    end = time.time()\n",
    "    return dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# builds the neural network for a given class\n",
    "def neural_network(class_data):\n",
    "    num_train = []\n",
    "    num_label = []\n",
    "    for x in class_data:\n",
    "        num_train.append(x[0])\n",
    "        num_label.append(x[1])\n",
    "    \n",
    "    num_train = np.array(num_train)\n",
    "    num_label = np.array(num_label)\n",
    "    \n",
    "    # converting categorical variable into numerical values\n",
    "    encoder = LabelEncoder()\n",
    "    encoder.fit(num_label)\n",
    "\n",
    "    # code: 0 - draw; 1 - loss; 2 -win\n",
    "    encoded_Y = encoder.transform(num_label)\n",
    "    final_label = np_utils.to_categorical(encoded_Y, 3)\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(8, input_dim=42, activation='relu'))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', \\\n",
    "                  optimizer='adam', metrics=['accuracy'])\n",
    "    model.fit(num_train, final_label, epochs=5, batch_size=5)\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# builds the neural shrub\n",
    "def neural_shrubs(tree, train, label):\n",
    "    train = np.array(train)\n",
    "    label = np.array(label)\n",
    "  \n",
    "    # leave_id: index of the leaf that cantains the instance\n",
    "    leave_id = tree.apply(train) \n",
    "\n",
    "    num_class = 3\n",
    "    classes = [[] for i in range(0, num_class)] \n",
    "\n",
    "    for x in range(len(train)):\n",
    "        leaf = leave_id[x]\n",
    "        \n",
    "        # Gets the class for each leaf\n",
    "        #.value: returns the distributition at the leaf, \n",
    "        #        i.e number of instance in each class at that leaf\n",
    "        #.argmax(): returns the class which has the max instance\n",
    "        #        i.e here: (0, 1, 2) - it is 0-indexed\n",
    "        idx = np.array(tree.tree_.value[leaf]).argmax() \n",
    "\n",
    "        # insert the instance into the class\n",
    "        classes[idx].append([train[x], label[x]])\n",
    "    \n",
    "    # stores the neural network for each class\n",
    "    nn_models = []\n",
    "    \n",
    "    #stores the max time taken to build a neural network\n",
    "    max_time = 0;\n",
    "\n",
    "    for x in range(num_class):\n",
    "        \n",
    "        start = time.time()\n",
    "        model = neural_network(classes[x])\n",
    "        end = time.time()\n",
    "        \n",
    "        time_taken = end - start\n",
    "        if max_time < time_taken:\n",
    "            max_time = time_taken\n",
    "            \n",
    "        nn_models.append(model)\n",
    "\n",
    "    # returns a neural network for each class and the max \n",
    "    # time taken to build the neural network\n",
    "    return nn_models, max_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "211/211 [==============================] - 0s 2ms/step - loss: 1.1439 - acc: 0.3175\n",
      "Epoch 2/5\n",
      "211/211 [==============================] - 0s 467us/step - loss: 1.1121 - acc: 0.3318\n",
      "Epoch 3/5\n",
      "211/211 [==============================] - 0s 402us/step - loss: 1.0909 - acc: 0.3412\n",
      "Epoch 4/5\n",
      "211/211 [==============================] - 0s 429us/step - loss: 1.0761 - acc: 0.3697\n",
      "Epoch 5/5\n",
      "211/211 [==============================] - 0s 472us/step - loss: 1.0619 - acc: 0.3981\n",
      "Epoch 1/5\n",
      "12442/12442 [==============================] - 5s 401us/step - loss: 0.8540 - acc: 0.6231\n",
      "Epoch 2/5\n",
      "12442/12442 [==============================] - 5s 378us/step - loss: 0.7480 - acc: 0.6857\n",
      "Epoch 3/5\n",
      "12442/12442 [==============================] - 5s 383us/step - loss: 0.7267 - acc: 0.6926\n",
      "Epoch 4/5\n",
      "12442/12442 [==============================] - 5s 379us/step - loss: 0.7152 - acc: 0.6968\n",
      "Epoch 5/5\n",
      "12442/12442 [==============================] - 5s 387us/step - loss: 0.7084 - acc: 0.7009\n",
      "Epoch 1/5\n",
      "41392/41392 [==============================] - 17s 421us/step - loss: 0.5751 - acc: 0.7783\n",
      "Epoch 2/5\n",
      "41392/41392 [==============================] - 17s 405us/step - loss: 0.5110 - acc: 0.7998\n",
      "Epoch 3/5\n",
      "41392/41392 [==============================] - 17s 406us/step - loss: 0.5002 - acc: 0.8026\n",
      "Epoch 4/5\n",
      "41392/41392 [==============================] - 17s 402us/step - loss: 0.4935 - acc: 0.8048\n",
      "Epoch 5/5\n",
      "41392/41392 [==============================] - 17s 403us/step - loss: 0.4885 - acc: 0.8071\n"
     ]
    }
   ],
   "source": [
    "# The algorithm to build the neural shrub\n",
    "train, train_label, test, test_label = get_data()\n",
    "\n",
    "dt_start = time.time()\n",
    "tree = decision_tree(train, train_label)\n",
    "dt_end = time.time()\n",
    "\n",
    "shrubs, max_time = neural_shrubs(tree, train, train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicts using the neural shrub\n",
    "def neural_shrub_predict(tree, nn_model, test, label):\n",
    "    label_test = np.array(label)\n",
    "    test = np.array(test)\n",
    "    \n",
    "    #row - actual; col - pred\n",
    "    confusion_matrix = np.array([[0, 0, 0], [0, 0, 0], [0, 0, 0]])\n",
    "    correct = 0\n",
    "    \n",
    "    for i in range(len(test)):\n",
    "        x = test[i]\n",
    "        pred_class = tree.predict([x])\n",
    "        x = np.array([x])\n",
    "        pred = pred_class[0]\n",
    "        nn_model_class = nn_model[pred_class[0]]\n",
    "        pred = np.argmax(nn_model_class.predict(x))\n",
    "\n",
    "        confusion_matrix[label[i]][pred] = \\\n",
    "            confusion_matrix[label[i]][pred] + 1\n",
    "        if pred == label[i]: correct = correct + 1\n",
    "\n",
    "    acc_score = correct/len(test)\n",
    "    \n",
    "    return confusion_matrix, acc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "\n",
      " [[  62  345  838]\n",
      " [  46 2261 1083]\n",
      " [  35  674 8168]]\n"
     ]
    }
   ],
   "source": [
    "# Predicting\n",
    "cm, acc_score = neural_shrub_predict(tree, shrubs, test, test_label)\n",
    "print(\"Confusion Matrix:\\n\\n\", cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function used to calcultate the metrics for each class\n",
    "def metrics(cm, cls, size):\n",
    "    cm = np.array(cm)\n",
    "    tp = cm[cls][cls]\n",
    "    fp = sum(cm[x, cls] for x in range(3))-cm[cls][cls]\n",
    "    fn = sum(cm[cls, x] for x in range(3))-cm[cls][cls]\n",
    "    tn = size - tp - fp - fn\n",
    "    precision = tp/(tp+fp)\n",
    "    recall = tp/(tp+fn)\n",
    "    fmeasure = 2*(precision*recall)/(precision + recall)\n",
    "    accuracy = (tp + tn)/size\n",
    "    \n",
    "    return precision, recall, fmeasure, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Precision Recall F-measure Accuracy\n",
      "Class 0 (draw):  0.434    0.05   0.089     0.906\n"
     ]
    }
   ],
   "source": [
    "# metrics for class 0 (draw)\n",
    "precision0, recall0, f0, acc0 = metrics(cm, 0, len(test))\n",
    "print(\"                Precision Recall F-measure Accuracy\")\n",
    "print(\"Class 0 (draw): \", round(precision0, 3), \"  \", round(recall0, 3), \\\n",
    "      \" \", round(f0, 3), \"   \", round(acc0,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Precision Recall F-measure Accuracy\n",
      "Class 1 (loss):  0.689    0.667   0.678     0.841\n"
     ]
    }
   ],
   "source": [
    "# metrics for class 1 (lose)\n",
    "precision1, recall1, f1, acc1 = metrics(cm, 1, len(test))\n",
    "print(\"                Precision Recall F-measure Accuracy\")\n",
    "print(\"Class 1 (loss): \", round(precision1, 3), \"  \", round(recall1, 3), \\\n",
    "      \" \", round(f1, 3), \"   \", round(acc1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Precision Recall F-measure Accuracy\n",
      "Class 2 (win):  0.81    0.92   0.861     0.805\n"
     ]
    }
   ],
   "source": [
    "# metrics for class 2 (win)\n",
    "precision2, recall2, f2, acc2 = metrics(cm, 2, len(test))\n",
    "print(\"                Precision Recall F-measure Accuracy\")\n",
    "print(\"Class 2 (win): \", round(precision2, 3), \"  \", round(recall2, 3), \\\n",
    "      \" \", round(f2, 3), \"   \", round(acc2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Precision Recall F-measure Accuracy\n",
      "Average:  0.644    0.546   0.543     0.851\n"
     ]
    }
   ],
   "source": [
    "# average metrics\n",
    "avg_p = (precision0 + precision1 + precision2)/3.0\n",
    "avg_r = (recall0 + recall1 + recall2) / 3.0\n",
    "avg_f = (f0 + f1 + f2) / 3.0\n",
    "avg_a = (acc0 + acc1 + acc2)/ 3.0\n",
    "print(\"        Precision Recall F-measure Accuracy\")\n",
    "print(\"Average: \", round(avg_p, 3), \"  \", round(avg_r, 3), \\\n",
    "      \" \", round(avg_f, 3), \"   \", round(avg_a,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Time: 84.82363 sec\n"
     ]
    }
   ],
   "source": [
    "# training time\n",
    "total_time_taken = dt_end - dt_start + max_time\n",
    "print(\"Training Time: %s sec\" % round(total_time_taken, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy_score:  0.77642\n"
     ]
    }
   ],
   "source": [
    "# Number of instances correctly classified\n",
    "print(\"Accuracy_score: \", round(acc_score, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
