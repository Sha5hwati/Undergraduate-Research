{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Shrub - Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shashwati/anaconda3/envs/py35/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os, sys\n",
    "import string\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from keras.utils import np_utils\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras import Sequential\n",
    "from keras import layers\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(dataset):\n",
    "    if os.path.isfile(dataset):\n",
    "        print(\"Loading \", dataset, \" dataset ...\")\n",
    "        data = pd.read_csv(dataset)\n",
    "        print(\"\\nDataset loaded successfully\\n\\n\")\n",
    "        return data\n",
    "    else:\n",
    "        print('File not found')\n",
    "        print('\\n\\nExiting...')\n",
    "        sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The column names are [a, b, c, ..., z, A, B, C, ..., W]\n",
    "columnNames = list(string.ascii_lowercase) \\\n",
    "              + list(string.ascii_uppercase)[:23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():   \n",
    "    train_dataset = load_data('./sensIT_train.csv')\n",
    "    label_train = train_dataset['result']\n",
    "    train = train_dataset[columnNames]\n",
    "\n",
    "    test_dataset = load_data('./sensIT_test.csv')\n",
    "    label_test = test_dataset['result']\n",
    "    test = test_dataset[columnNames]\n",
    "    \n",
    "    return train, label_train, test, label_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree._tree import TREE_LEAF\n",
    "\n",
    "def prune_index(inner_tree, index, threshold):\n",
    "    if inner_tree.value[index].min() < threshold:\n",
    "        # turn node into a leaf by \"unlinking\" its children\n",
    "        inner_tree.children_left[index] = TREE_LEAF\n",
    "        inner_tree.children_right[index] = TREE_LEAF\n",
    "    # if there are shildren, visit them as well\n",
    "    if inner_tree.children_left[index] != TREE_LEAF:\n",
    "        prune_index(inner_tree, inner_tree.children_left[index], threshold)\n",
    "        prune_index(inner_tree, inner_tree.children_right[index], threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Makes the decision tree\n",
    "def decision_tree(train, label):\n",
    "    dt = DecisionTreeClassifier(max_depth = 8, min_samples_leaf=500, random_state = 1)\n",
    "    dt.fit(train, label)\n",
    "    prune_index(dt.tree_, 0, 5)\n",
    "    return dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class_data: list of instances belonging to a class\n",
    "# Each instance consists of the predictor_values and the actual class\n",
    "def neural_network(class_data):\n",
    "    nn_train = []\n",
    "    nn_label = []\n",
    "\n",
    "    for instance in class_data:\n",
    "        nn_train.append(instance[0]) # predictor\n",
    "        nn_label.append(instance[1]) # actual class\n",
    "    \n",
    "    nn_train = np.array(nn_train)\n",
    "    nn_label = np.array(nn_label)\n",
    "\n",
    "    # Preprocessing\n",
    "    encoder = LabelEncoder()\n",
    "    encoder.fit(nn_label)\n",
    "    nn_label = encoder.transform(nn_label)\n",
    "    nn_label = np_utils.to_categorical(nn_label)\n",
    "        \n",
    "    # Neural network structure\n",
    "    model = Sequential()\n",
    "    model.add(layers.Dense(30,init = 'uniform', activation = 'relu', input_dim = 49))\n",
    "    model.add(layers.Dense(10,init = 'uniform', activation = 'relu'))\n",
    "    model.add(layers.Dense(3, init = 'uniform', activation = 'softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
    "    model.fit(nn_train, nn_label, epochs=15, batch_size=500)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_shrubs(tree, train, label):\n",
    "    train = np.array(train)\n",
    "    label = np.array(label)\n",
    "  \n",
    "    # leave_id: index of the leaf that cantains the instance\n",
    "    leave_id = tree.apply(train) \n",
    "\n",
    "    num_class = 3\n",
    "    classes = [[] for i in range(0, num_class)] \n",
    "\n",
    "    for x in range(len(train)):\n",
    "        leaf = leave_id[x]\n",
    "        \n",
    "        # Gets the class for each leaf\n",
    "        #.value: returns the distributition at the leaf, \n",
    "        #        i.e number of instance in each class at that leaf\n",
    "        #.argmax(): returns the class which has the max instance\n",
    "        #        i.e here: (0, 1, 2) - it is 0-indexed\n",
    "        idx = np.array(tree.tree_.value[leaf]).argmax() \n",
    "\n",
    "        # insert the instance into the class\n",
    "        classes[idx].append([train[x], label[x]])\n",
    "    \n",
    "    # stores the neural network for each class\n",
    "    nn_models = []\n",
    "    \n",
    "    #stores the max time taken to build a neural network\n",
    "    max_time = 0;\n",
    "\n",
    "    for x in range(num_class):\n",
    "        start = time.time()\n",
    "        model = neural_network(classes[x])\n",
    "        end = time.time()\n",
    "        \n",
    "        time_taken = end - start\n",
    "        if max_time < time_taken:\n",
    "            max_time = time_taken\n",
    "            \n",
    "        nn_models.append(model)\n",
    "\n",
    "    # returns a neural network for each class and the max \n",
    "    # time taken to build the neural network\n",
    "    return nn_models, max_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading  ./sensIT_train.csv  dataset ...\n",
      "\n",
      "Dataset loaded successfully\n",
      "\n",
      "\n",
      "Loading  ./sensIT_test.csv  dataset ...\n",
      "\n",
      "Dataset loaded successfully\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shashwati/anaconda3/envs/py35/lib/python3.5/site-packages/ipykernel_launcher.py:22: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(30, activation=\"relu\", input_dim=49, kernel_initializer=\"uniform\")`\n",
      "/home/shashwati/anaconda3/envs/py35/lib/python3.5/site-packages/ipykernel_launcher.py:23: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(10, activation=\"relu\", kernel_initializer=\"uniform\")`\n",
      "/home/shashwati/anaconda3/envs/py35/lib/python3.5/site-packages/ipykernel_launcher.py:24: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(3, activation=\"softmax\", kernel_initializer=\"uniform\")`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "20271/20271 [==============================] - 1s 49us/step - loss: 1.0812 - acc: 0.5889\n",
      "Epoch 2/15\n",
      "20271/20271 [==============================] - 0s 15us/step - loss: 0.9867 - acc: 0.5978\n",
      "Epoch 3/15\n",
      "20271/20271 [==============================] - 0s 16us/step - loss: 0.9305 - acc: 0.5978\n",
      "Epoch 4/15\n",
      "20271/20271 [==============================] - 0s 16us/step - loss: 0.9140 - acc: 0.5978\n",
      "Epoch 5/15\n",
      "20271/20271 [==============================] - 0s 15us/step - loss: 0.9039 - acc: 0.6023\n",
      "Epoch 6/15\n",
      "20271/20271 [==============================] - 0s 18us/step - loss: 0.8977 - acc: 0.6058\n",
      "Epoch 7/15\n",
      "20271/20271 [==============================] - 0s 18us/step - loss: 0.8934 - acc: 0.6073\n",
      "Epoch 8/15\n",
      "20271/20271 [==============================] - 0s 15us/step - loss: 0.8909 - acc: 0.6083\n",
      "Epoch 9/15\n",
      "20271/20271 [==============================] - 0s 17us/step - loss: 0.8894 - acc: 0.6072\n",
      "Epoch 10/15\n",
      "20271/20271 [==============================] - 0s 16us/step - loss: 0.8880 - acc: 0.6073\n",
      "Epoch 11/15\n",
      "20271/20271 [==============================] - 0s 19us/step - loss: 0.8865 - acc: 0.6081\n",
      "Epoch 12/15\n",
      "20271/20271 [==============================] - 0s 11us/step - loss: 0.8853 - acc: 0.6079\n",
      "Epoch 13/15\n",
      "20271/20271 [==============================] - 0s 20us/step - loss: 0.8840 - acc: 0.6073\n",
      "Epoch 14/15\n",
      "20271/20271 [==============================] - 0s 16us/step - loss: 0.8829 - acc: 0.6077\n",
      "Epoch 15/15\n",
      "20271/20271 [==============================] - 1s 30us/step - loss: 0.8819 - acc: 0.6087\n",
      "Epoch 1/15\n",
      "23943/23943 [==============================] - 1s 39us/step - loss: 1.0781 - acc: 0.5265\n",
      "Epoch 2/15\n",
      "23943/23943 [==============================] - 0s 10us/step - loss: 1.0132 - acc: 0.5310\n",
      "Epoch 3/15\n",
      "23943/23943 [==============================] - 0s 11us/step - loss: 1.0065 - acc: 0.5310\n",
      "Epoch 4/15\n",
      "23943/23943 [==============================] - 0s 10us/step - loss: 1.0031 - acc: 0.5316\n",
      "Epoch 5/15\n",
      "23943/23943 [==============================] - 0s 10us/step - loss: 0.9934 - acc: 0.5350\n",
      "Epoch 6/15\n",
      "23943/23943 [==============================] - 0s 19us/step - loss: 0.9758 - acc: 0.5439\n",
      "Epoch 7/15\n",
      "23943/23943 [==============================] - 0s 13us/step - loss: 0.9636 - acc: 0.5490\n",
      "Epoch 8/15\n",
      "23943/23943 [==============================] - 0s 10us/step - loss: 0.9578 - acc: 0.5512\n",
      "Epoch 9/15\n",
      "23943/23943 [==============================] - 0s 10us/step - loss: 0.9541 - acc: 0.5545\n",
      "Epoch 10/15\n",
      "23943/23943 [==============================] - 0s 11us/step - loss: 0.9510 - acc: 0.5562\n",
      "Epoch 11/15\n",
      "23943/23943 [==============================] - 0s 13us/step - loss: 0.9483 - acc: 0.5592\n",
      "Epoch 12/15\n",
      "23943/23943 [==============================] - 0s 10us/step - loss: 0.9467 - acc: 0.5591\n",
      "Epoch 13/15\n",
      "23943/23943 [==============================] - 0s 10us/step - loss: 0.9432 - acc: 0.5601\n",
      "Epoch 14/15\n",
      "23943/23943 [==============================] - 0s 14us/step - loss: 0.9413 - acc: 0.5612\n",
      "Epoch 15/15\n",
      "23943/23943 [==============================] - 0s 15us/step - loss: 0.9396 - acc: 0.5622\n",
      "Epoch 1/15\n",
      "34609/34609 [==============================] - 1s 34us/step - loss: 0.9702 - acc: 0.8717\n",
      "Epoch 2/15\n",
      "34609/34609 [==============================] - 0s 12us/step - loss: 0.5252 - acc: 0.8733\n",
      "Epoch 3/15\n",
      "34609/34609 [==============================] - 1s 15us/step - loss: 0.3897 - acc: 0.8733\n",
      "Epoch 4/15\n",
      "34609/34609 [==============================] - 1s 19us/step - loss: 0.3500 - acc: 0.8733\n",
      "Epoch 5/15\n",
      "34609/34609 [==============================] - 1s 15us/step - loss: 0.3378 - acc: 0.8733\n",
      "Epoch 6/15\n",
      "34609/34609 [==============================] - 0s 14us/step - loss: 0.3293 - acc: 0.8733\n",
      "Epoch 7/15\n",
      "34609/34609 [==============================] - 1s 15us/step - loss: 0.3227 - acc: 0.8733\n",
      "Epoch 8/15\n",
      "34609/34609 [==============================] - 0s 14us/step - loss: 0.3183 - acc: 0.8734\n",
      "Epoch 9/15\n",
      "34609/34609 [==============================] - 1s 15us/step - loss: 0.3153 - acc: 0.8754\n",
      "Epoch 10/15\n",
      "34609/34609 [==============================] - 1s 14us/step - loss: 0.3130 - acc: 0.8768\n",
      "Epoch 11/15\n",
      "34609/34609 [==============================] - 0s 11us/step - loss: 0.3112 - acc: 0.8779\n",
      "Epoch 12/15\n",
      "34609/34609 [==============================] - 0s 13us/step - loss: 0.3098 - acc: 0.8799\n",
      "Epoch 13/15\n",
      "34609/34609 [==============================] - 0s 12us/step - loss: 0.3085 - acc: 0.8802\n",
      "Epoch 14/15\n",
      "34609/34609 [==============================] - 0s 14us/step - loss: 0.3075 - acc: 0.8813\n",
      "Epoch 15/15\n",
      "34609/34609 [==============================] - 1s 17us/step - loss: 0.3063 - acc: 0.8819\n"
     ]
    }
   ],
   "source": [
    "# The algorithm to build the neural shrub\n",
    "train, train_label, test, test_label = get_data()\n",
    "\n",
    "dt_start = time.time()\n",
    "tree = decision_tree(train, train_label)\n",
    "dt_end = time.time()\n",
    "\n",
    "shrubs, max_time = neural_shrubs(tree, train, train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_shrub_predict(tree, nn_model, test, label):\n",
    "    label_test = np.array(label)\n",
    "    test = np.array(test)\n",
    "    \n",
    "    #row - actual; col - pred\n",
    "    confusion_matrix = np.array([[0, 0, 0], [0, 0, 0], [0, 0, 0]])\n",
    "    correct = 0\n",
    "    \n",
    "    for i in range(len(test)):\n",
    "        x = test[i]\n",
    "        pred_class = tree.predict([x])\n",
    "        x = np.array([x])\n",
    "        nn_model_class = nn_model[pred_class[0] - 1]\n",
    "        pred = np.argmax(nn_model_class.predict(x))+1\n",
    "\n",
    "        confusion_matrix[label[i]-1][pred-1] = confusion_matrix[label[i]-1][pred-1] + 1\n",
    "        if pred == label[i]: correct = correct + 1\n",
    "\n",
    "    acc_score = correct/len(test)\n",
    "    \n",
    "    return confusion_matrix, acc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "\n",
      " [[2808 1617  178]\n",
      " [ 994 3458  858]\n",
      " [ 668 1527 7597]]\n"
     ]
    }
   ],
   "source": [
    "# Predicting\n",
    "cm, acc_score = neural_shrub_predict(tree, shrubs, test, test_label)\n",
    "print(\"Confusion Matrix:\\n\\n\", cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(cm, cls, size):\n",
    "    cm = np.array(cm)\n",
    "    tp = cm[cls][cls]\n",
    "    fp = sum(cm[x, cls] for x in range(3))-cm[cls][cls]\n",
    "    fn = sum(cm[cls, x] for x in range(3))-cm[cls][cls]\n",
    "    tn = size - tp - fp - fn\n",
    "    precision = tp/(tp+fp)\n",
    "    recall = tp/(tp+fn)\n",
    "    fmeasure = 2*(precision*recall)/(precision + recall)\n",
    "    accuracy = (tp + tn)/size\n",
    "    \n",
    "    return precision, recall, fmeasure, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Precision Recall F-measure Accuracy\n",
      "Class 1:  0.628    0.61   0.619     0.825\n"
     ]
    }
   ],
   "source": [
    "# Class 1\n",
    "precision0, recall0, f0, acc0 = metrics(cm, 0, len(test))\n",
    "print(\"        Precision Recall F-measure Accuracy\")\n",
    "print(\"Class 1: \", round(precision0, 3), \"  \", round(recall0, 3), \\\n",
    "      \" \", round(f0, 3), \"   \", round(acc0,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Precision Recall F-measure Accuracy\n",
      "Class 2:  0.524    0.651   0.581     0.746\n"
     ]
    }
   ],
   "source": [
    "# Class 2\n",
    "precision1, recall1, f1, acc1 = metrics(cm, 1, len(test))\n",
    "print(\"        Precision Recall F-measure Accuracy\")\n",
    "print(\"Class 2: \", round(precision1, 3), \"  \", round(recall1, 3), \\\n",
    "      \" \", round(f1, 3), \"   \", round(acc1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Precision Recall F-measure Accuracy\n",
      "Class 3:  0.88    0.776   0.825     0.836\n"
     ]
    }
   ],
   "source": [
    "# Class 3\n",
    "precision2, recall2, f2, acc2 = metrics(cm, 2, len(test))\n",
    "print(\"        Precision Recall F-measure Accuracy\")\n",
    "print(\"Class 3: \", round(precision2, 3), \"  \", round(recall2, 3), \\\n",
    "      \" \", round(f2, 3), \"   \", round(acc2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Precision Recall F-measure Accuracy\n",
      "Average:  0.677    0.679   0.675     0.802\n"
     ]
    }
   ],
   "source": [
    "avg_p = (precision0 + precision1 + precision2)/3.0\n",
    "avg_r = (recall0 + recall1 + recall2) / 3.0\n",
    "avg_f = (f0 + f1 + f2) / 3.0\n",
    "avg_a = (acc0 + acc1 + acc2)/ 3.0\n",
    "print(\"        Precision Recall F-measure Accuracy\")\n",
    "print(\"Average: \", round(avg_p, 3), \"  \", round(avg_r, 3), \\\n",
    "      \" \", round(avg_f, 3), \"   \", round(avg_a,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy_score:  0.7035\n",
      "Training Time: 12.572 secs\n"
     ]
    }
   ],
   "source": [
    "# Number of instances correctly classified\n",
    "print(\"Accuracy_score: \", round(acc_score, 4))\n",
    "total_time_taken = dt_end - dt_start + max_time\n",
    "print(\"Training Time: %s secs\" % round(total_time_taken, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
